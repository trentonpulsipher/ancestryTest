---
title: "Data Discovery"
subtitle: "Ancestry Product Analytics Homework Assignment"
author: "Trenton Pulsipher"
date: "`r lubridate::today()`"
output: html_document
---


```{r settings, echo = F, warning = F, message = F, error = F}
knitr::opts_chunk$set(
  echo = F,
  message = F,
  warning = F,
  error = F,
  fig.height = 3,
  fig.width = 9.5,
  cache = F
)

# Libraries 
library(lubridate)
library(stopwords)
library(tidyverse)
library(trelliscopejs)
library(wordcloud)
library(HSPSUtils) # install_github("HSPS-DataScience/HSPSUtils")
                   # devtools::update_packages("HSPSUtils")
library(rbokeh)
library(ggpubr)
```


```{r dataIn}
# Read in Data
data <- read_csv("~/Documents/Development/R/data/ancestryTest/take-home_exercise_data.csv") %>%
  select(-X1) %>%
  rename(customer_type_grp = customer_type_group)

# fix the mislabeled regtenure 20 day group
data$regtenure[data$regtenure == "<=20 day"] <- "<=20 days"
```


## Initial Look at Data

### Dataset 

Below are 100 randomly selected rows from the dataset. 

```{r dataTable}
create_datetable <- function(data) {
  ## data table
  DT::datatable(
    data %>%
      sample_n(100),
      options = list(
        pageLength = 5,
        searching = T,
        scrollX = T
      )
    )
}
create_datetable(data)
```


### Data Summary

The table below shows several metrics calculated against the various columns/variables. These metrics include: the number of unique values, number of NAs, the maximum value, the minimum value, and the mean/average.
```{r dataSummary}
create_data_summary <- function(data) {
  # convert column names for use here
  names(data) <- str_replace_all(names(data), "_", ".")

  # Data Summary
  data_summary <- data %>%
    # select_if(is.numeric) %>%
    summarise_all(funs(
      numUnique = length(unique(.)),
      nas = sum(is.na(.)),
      max = max(., na.rm = T),
      min = min(., na.rm = T),
      mean = mean(., na.rm = T))) %>%
    gather() %>%
    separate(key, c("key", "stat"), sep = "_") %>%
    spread(key, value)
  # generate datatable from summary
  DT::datatable(
    data_summary,
    options = list(
      pageLength = 5,
      searching = T,
      scrollX = T
    )
  )
}
create_data_summary(data)
```


### Categorical Variables in Bar Charts

```{r catBarCharts, fig.height = 8}
create_bar_chart_categorical_trelli <- function(data) {
    data %>%
    # selection of categorical variables isn't automated yet
      select(xsell_gsa, regtenure, customer_type_grp, daystogetresult_grp, 
             dna_visittrafficsubtype) %>%
      gather_group_by_count() %>%
      ungroup() %>%
    ggplot(aes(x = value, y = Count)) +
      geom_bar(stat = "identity", alpha = 0.5) +
      geom_text(aes(label = scales::comma(Count))) +
      theme_bw() +
      coord_flip() +
      labs(x = "", y = "") +
      facet_wrap(~key, scales = "free")
      # facet_trelliscope(~ key,
      #                   scales = "free",
      #                   self_contained = T,
      #                   width = 600,
      #                   name = "categoricalVariables",
      #                   group = "vars",
      #                   desc = "All Variables of Type Character or Factor")
}
create_bar_chart_categorical_trelli(data)
```


### Numeric Variables in Histograms

```{r numHistograms}
create_hist_numeric <- function(data) {
  ## histogram of all numeric variables
  data %>%
    select(xsell_day_exact) %>%
    # select_if(is.numeric) %>%
    # .select_non_id_columns() %>%
    gather() %>%
    filter(value >= 0) %>%
  ggplot(aes(x = value)) +
    geom_histogram(binwidth = .25, bins = 30) +
    scale_y_continuous(labels = scales::comma) +
    scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000, 10000),
                  labels = c(0.1, 1, 10, 100, 1000, 10000)) +
    facet_wrap(~ key, scales = "free", ncol = 3) +
    theme_bw()
}
create_hist_numeric(data)
```


### Time Series Variables

```{r ts1, fig.height = 4}
create_time_series <- function(data) {
  # time series
  data %>%
    select_if(is.Date) %>%
    gather_group_by_count() %>%
    ungroup() %>%
    figure(xlab = "") %>%
      ly_points(x = value, y = Count,
               hover = list(
                 Date = value, Count = Count
               ))
  # ggplot(aes(x = value, y = Count)) +
  #   geom_line() +
  #   geom_smooth(method = "loess") +
  #   theme_bw() +
  #   facet_wrap(~ key, scales = "free") + 
  #   labs(x = "")
}
create_time_series(data %>% select(ordercreatedate))
```

```{r ts2, fig.height = 4}
create_time_series(data %>% select(dnatestactivationdayid))
```


## Outliers and Notes

* ID variables
    + ```r data %>% group_by(prospectid) %>% mutate(Count = n()) %>% filter(Count > 1) %>% pull(prospectid) %>% unique() %>% length() %>% scales::comma()``` **prospectid**s appear multiple times, accounting for ```r data %>% group_by(prospectid) %>% mutate(Count = n()) %>% filter(Count > 1) %>% pull(prospectid) %>% length() %>% scales::comma()``` rows in the dataset.
* Categorical variables
    + **dna_visittrafficsubtype** has roughly 15 non-NA subtypes over 2000, meaning many subtypes contain very few (for some it's almost no) observations in this dataset. May prefer to combine subtypes later.
    + Treating **xsell_gsa** as categorical.
* Numeric variables
    + **xsell_day_exact** appears to have a funky distribution, quite log looking. However, the histogram does ignore any zero values, which is roughly ```r round((data %>% select(xsell_day_exact) %>% filter(xsell_day_exact == 0) %>% count()) / ((data %>% select(xsell_day_exact) %>% filter(xsell_day_exact == 0) %>% count()) + (data %>% select(xsell_day_exact) %>% filter(xsell_day_exact != 0) %>% count())), 3) * 100```% of the values for that variable. May want to look at a cummulative view of some kind.
* Time series variables
    + **ordercreatedate** has a date of `r data %>% select(ordercreatedate) %>% filter(ordercreatedate < "2000-01-01") %>% slice(1) %>% pull()` repeated `r data %>% select(ordercreatedate) %>% filter(ordercreatedate < "2000-01-01") %>% count() %>% pull()` times in the dataset. (Suggest removing these from the dataset.)
    + **dnatestactivationdayid** has `r round((data %>% select(dnatestactivationdayid) %>% filter(is.na(dnatestactivationdayid)) %>% count()) / (data %>% select(dnatestactivationdayid) %>% count()), 3) * 100 `% of the values as NA.


### Categorial Variable Notes

A closer look at dna_visittrafficsubtype shows that many of the subtypes are rarely found in this dataset. Grouping or combining these in a meaningful manner may help, but unfortunately I doubt I have sufficient information or experience to group the levels of this variable.
```{r tblVisitTraffic}
DT::datatable(
  data %>% 
        group_by(dna_visittrafficsubtype) %>% 
        summarise(Count = n()) %>% 
        mutate(
          
          Percent = 100 * (Count / sum(Count))
        ) %>% 
        arrange(desc(Percent)),
  options = list(
    pageLength = 10,
    searching = T,
    scrollX = T
  )
)
```


### Time Series Variables (improved)

After removing the outlier dates (noted above) for ordercreatedate we can better see the general trend.
```{r tsImproved1, fig.height = 4}
create_time_series(data %>% 
                     filter(
                       ordercreatedate > "2000-01-01",
                       !is.na(dnatestactivationdayid)
                     ) %>%
                     select(ordercreatedate)
                   )
```

After removing the NAs from dnatestactivationdayid we can better see the general trend.
```{r tsImproved2, fig.height = 4}
create_time_series(data %>% 
                     filter(
                       ordercreatedate > "2000-01-01",
                       !is.na(dnatestactivationdayid)
                     ) %>%
                     select(dnatestactivationdayid)
                   )
```



### Cross-sell Percentage

##### Daily Trend

Variance appears to tighten up in 2016-2017 and the obvious drop in late 2016 to 2017 will cause problems for most models. Forecasting or predicting could prove difficult if the model isn't able to account for the sudden drop.

```{r dailyPct}
data %>%
  filter(ordercreatedate > "2000-01-01") %>%
  group_by(ordercreatedate) %>%
  mutate(
    xsell_120rule = if_else(xsell_day_exact <= 120, 1, 0),
    xsell = if_else(xsell_120rule & xsell_gsa, 1, 0)
  ) %>%
  summarise(PercentConverted = sum(xsell) / length(xsell)) %>%
  ggplot(aes(x = ordercreatedate, y = PercentConverted)) +
    geom_point(alpha = 0.25) +
    scale_y_continuous(limits = c(0,1), 
                       breaks = seq(0,1,by=.2), 
                       labels = paste0(seq(0,1,by=.2)*100, "%")) +
    theme_bw() +
    labs(x = "", y = "Percent",
         title = "Percent of DNA Orders Created Converted to Xsell")
```

A more detailed view of this daily xsell conversion may help us understand what is influencing this behavior and how that might affect model construction.

```{r dailyPctByVars1, fig.height = 4}
# dailyPctByVar <- function(data, facetVar) {
#   data %>%
#     filter(ordercreatedate > "2000-01-01") %>%
#     group_by(ordercreatedate, one_of(facetVar)) %>%
#     mutate(
#       xsell_120rule = if_else(xsell_day_exact <= 120, 1, 0),
#       xsell = if_else(xsell_120rule & xsell_gsa, 1, 0)
#     ) %>%
#     summarise(PercentConverted = sum(xsell) / length(xsell)) %>%
#     ggplot(aes(x = ordercreatedate, y = PercentConverted)) +
#     geom_point(alpha = 0.25) +
#     scale_y_continuous(breaks = seq(0,1,by=.2), labels = paste0(seq(0,1,by=.2)*100, "%")) +
#     facet_wrap(~ one_of(facetVar)) +
#     theme_bw() +
#     labs(x = "", y = "Percent",
#          title = "Percent of DNA Orders Created Converted to Xsell")
# }
# dailyPctByVar(data, facetVar = "customer_type_group")

  data %>%
    filter(ordercreatedate > "2000-01-01") %>%
    group_by(ordercreatedate, customer_type_grp) %>%
    mutate(
      xsell_120rule = if_else(xsell_day_exact <= 120, 1, 0),
      xsell = if_else(xsell_120rule & xsell_gsa, 1, 0)
    ) %>%
    summarise(PercentConverted = sum(xsell) / length(xsell)) %>%
    ggplot(aes(x = ordercreatedate, y = PercentConverted)) +
    geom_point(alpha = 0.25) +
    scale_y_continuous(limits = c(0,1), 
                       breaks = seq(0,1,by=.2), 
                       labels = paste0(seq(0,1,by=.2)*100, "%")) +
    facet_grid(customer_type_grp ~ .) +
    theme_bw() +
    theme(strip.text.x = element_text(angle = 0)) +
    labs(x = "", y = "Percent",
         title = "Percent of DNA Orders Created Converted to Xsell")
```

```{r dailyPctByRegtenure, fig.height = 4}
  data %>%
    filter(ordercreatedate > "2000-01-01") %>%
    mutate(regtenure = factor(regtenure, 
                              levels = c("No Reg Date", "Order prior to reg",
                                         "<=10 days", "<=20 days", "<=30 days",
                                         "<=60 days", "<=90 days", "<=120 days",
                                         "More than 120 days old"))) %>%
    group_by(ordercreatedate, regtenure) %>%
    mutate(
      xsell_120rule = if_else(xsell_day_exact <= 120, 1, 0),
      xsell = if_else(xsell_120rule & xsell_gsa, 1, 0)
    ) %>%
    summarise(PercentConverted = sum(xsell) / length(xsell)) %>%
    ggplot(aes(x = ordercreatedate, y = PercentConverted)) +
    geom_point(alpha = 0.25) +
    scale_y_continuous(limits = c(0,1), 
                       breaks = seq(0,1,by=.2), 
                       labels = paste0(seq(0,1,by=.2)*100, "%")) +
    facet_wrap(~ regtenure) +
    theme_bw() +
    labs(x = "", y = "Percent",
         title = "Percent of DNA Orders Created Converted to Xsell")
```


I must not understand the **regtenure** column yet.
```{r histExactVsRegtenure, fig.height = 4}
data %>% 
  filter(ordercreatedate > "2000-01-01") %>% 
    mutate(regtenure = factor(regtenure, 
                              levels = c("No Reg Date", "Order prior to reg",
                                         "<=10 days", "<=20 days", "<=30 days",
                                         "<=60 days", "<=90 days", "<=120 days",
                                         "More than 120 days old"))) %>%
  ggplot(aes(x = xsell_day_exact)) + 
    geom_histogram() + 
    theme_bw() + 
    facet_wrap(~regtenure, scales = "free")
```



